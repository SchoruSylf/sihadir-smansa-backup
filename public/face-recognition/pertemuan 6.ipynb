{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV ML \n",
    "\n",
    "- Intro Machine Learning\n",
    "- Intro OpenCV ML\n",
    "- Intro SVM Algorithm\n",
    "- SVM + LBPH For Facerecognition\n",
    "- Compare with Scikit-Learn Implementation\n",
    "- Hyperparameter tunning & search \n",
    "- Run Inference Model as MJPEG Stream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OpenCV `cv2.face` implementing a facial recognition system using Eigenface, Fisherface and Local Binary Pattern Histogram (LBPH).\n",
    "- Eigenface, Fisherface and LBPH used by `cv2.face` recognizer actualy just a **facial descriptior**.\n",
    "- **Facial Descriptor** is a proses creating **vector data** (numerical value) from the original data (image).\n",
    "- For example in LBPH the vector data is histogram value of LBP image. \n",
    "- Generally this stage is called **Feature Extraction**. \n",
    "> *if Eigenface, Fisherface and LBPH is only about createing a vector data, how the cv2.face recognize the face (classification)?*\n",
    "- LBPH in OpenCV is performed using a **nearest neighbour** classi-ﬁer in the computed feature space with metric **Chi square** as a dissimilarity mea-sure. *[-Face Recognition with Local Binary Patterns-](https://www.researchgate.net/publication/221304831_Face_Recognition_with_Local_Binary_Patterns)*<br>\n",
    "<img src=\"resource/Face-recognizers.png\" dtyle=\"width:400px\"></img>\n",
    "> *Is possible to use onother classifier for  facial decriptor like LPBH?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Intro Machine Learning\n",
    "- The study of computer algorithms that improve automatically through experience.[1][2]\n",
    "- It is seen as a subset of **artificial intelligence**. \n",
    "- Machine learning algorithms build a **mathematical model** based on **sample data**, known as \"training data\".\n",
    "- Machine learning is closely related to **computational statistics**, which focuses on making predictions using computers. \n",
    "\n",
    "> *Machine learning provides systems the ability to **automatically learn** and **improve from experience** without being **explicitly programmed**.*\n",
    "\n",
    "![](resource/machine_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "- In the case of tabular data, a data set corresponds to one or more database **tables**, where every **column** of a table represents a particular **variable/fature**, and each row corresponds to a **instance** data. <br>\n",
    "- Tabular dataset : <br>\n",
    "<img src=\"resource/text_dataset.png\" style=\"width:400px\"></img><br>\n",
    "- Image Dataset :<br>\n",
    "<img src=\"resource/image_dataset.png\" style=\"width:500px\"></img><br><br><br>\n",
    "- Dataset Proportion :<br>\n",
    "<img src=\"resource/dataset_proportion.jpeg\" style=\"width:500px\"></img>\n",
    "    - **Training set** : is used in training phase,\n",
    "    - **Validation set** : is used for validationg model during training, for example Cross Validation.\n",
    "    - **Test set** : is used in testing phase (after training model finish).\n",
    "- Common portion :\n",
    "    - Trainig set : 50%\n",
    "    - Validation set : 25%\n",
    "    - Test set : 25%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Algorithm\n",
    "<img src=\"resource/ml_algorithm.png\" style=\"width:500px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Machine Learning\n",
    "- **Classification**: Relates to **categorical data output**, such as whether it is red or not, whether the weather is sunny or cloudy, healthy or sick.\n",
    "- **Regression**: Relates to **continuous data output**, such as length, weight, velocity\n",
    "<img src=\"resource/supervised_learning.png\" style=\"width:500px\"></img>\n",
    "- Algorithm :\n",
    "    - Support Vector Machine (SVM)\n",
    "    - Linear Regression\n",
    "    - Logistic Regression\n",
    "    - Naive Bayes\n",
    "    - Linear Discriminant Analysis (LDA)\n",
    "    - Decision Tree\n",
    "    - K-nearest Neighbor\n",
    "    - Neural Network (Multilayer Perceptron)\n",
    "    - Similarity Learning\n",
    "    - Etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Intro OpenCV ML \n",
    "- Main Doc : https://docs.opencv.org/master/dc/dd6/ml_intro.html\n",
    "- List of Machine Learning Algorithm on OpenCV ML :\n",
    "    - Normal Bayes Classifier\n",
    "    - K-Nearest Neighbors (KNN)\n",
    "    - Support Vector Machines (SVM)\n",
    "    - Decision Trees\n",
    "    - Variable Importance\n",
    "    - Boosting\n",
    "    - Random Trees\n",
    "    - Expectation Maximization\n",
    "    - Neural Networks\n",
    "    - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "- Are supervised learning models with associated learning algorithms that analyze data used for **classification** and **regression analysis**.\n",
    "- Support Vector Machines is a **discriminative classifier** formally defined by a **separating hyperplane**. In other words, given labeled training data (supervised learning), the algorithm outputs an **optimal hyperplane** which categorizes new examples.\n",
    "- Developed at AT&T Bell Laboratories by Vapnik with colleagues (Boser et al., 1992, Guyon et al., 1993, Vapnik et al., 1997).\n",
    "- One of the most robust prediction methods, based on the statistical learning framework or VC theory proposed by Vapnik and Chervonenkis (1974) and Vapnik (1982, 1995).\n",
    "\n",
    "#### Linearly Separable Data\n",
    "- H1 does not separate the classes. \n",
    "- H2 does, but only with a small margin. \n",
    "- H3 separates them with the **maximal margin**.<br>\n",
    "\n",
    "<img src=\"resource/lineary_sparable.png\" style=\"width:250px\"></img>\n",
    "\n",
    "- **Maximum-margin hyperplane** and **margins** for an SVM trained with samples from two classes. \n",
    "- Samples on the margin are called the **support vectors**. <br>\n",
    "<img src=\"resource/SVM_margin.png\" style=\"width:250px\"></img>\n",
    "- Multiclass Dataset :<br>\n",
    "<img src=\"resource/multicalss_svm.png\" style=\"width:500px\"></img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM using OpenCV ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- setup dataset\n",
    "    - x_train : input data (4 samples , 2 feature data )\n",
    "    - y_train : output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(object=[[10, 10], \n",
    "                    [0, 10], \n",
    "                    [10, 0], \n",
    "                    [0, 0]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([ 10, \n",
    "                     10, \n",
    "                     0, \n",
    "                     0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train, s=200, cmap='rainbow')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documentation of SVM Model - OpenCV ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `cv.ml.SVM_create()` : create empty model SVM\n",
    "- method `.setType(svm_type)` :\n",
    "    - where `svm_type` :\n",
    "        - `cv2.ml.SVM_C_SVC` : $C$-Support Vector Classification. n-class classification (n ≥ 2), allows imperfect separation of classes.\n",
    "        - `cv2.ml.SVM_NU_SVC` : $ν$-Support Vector Classification. n-class classification with imperfect separation. Parameter $ν$ (0..1).\n",
    "        - `cv2.ml.SVM_ONE_CLASS` : Distribution Estimation (One-class SVM). \n",
    "        - `cv2.ml.SVM_EPS_SVR` : $ϵ$-Support Vector Regression. \n",
    "        - `cv2.ml.SVM_NU_SVR` : $ν$-Support Vector Regression. \n",
    "    - `svm_type` parameter :\n",
    "        - set $C$ (regularization parameter) if using C-SVC/NU-SVR/EPS-SVR : `.setC()`\n",
    "        - set $ϵ$ (epsilon) if using EPS-SVR : `.setP()`\n",
    "        - set $ν$ (nu) if using NU-SVC/NU-SVR/SVM-ONE_CLASS : `.setNU()`\n",
    "- method `.setKernel(kernel_type)` :\n",
    "    - where `kernel_type` :\n",
    "        - `cv2.ml.SVM_LINEAR` : Linear kernel, It is the fastest option\n",
    "        - `cv2.ml.SVM_POLY` : Polynomial kernel\n",
    "        - `cv2.ml.SVM_RBF` : Radial basis function (RBF), a good choice in most cases\n",
    "        - `cv2.ml.SVM_SIGMOID` : Sigmoid kernel\n",
    "    - Kernel Parameter :\n",
    "        - **linear** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: $\\langle x, x'\\rangle$\n",
    "        - **polynomial** &nbsp;&nbsp;&nbsp;&nbsp;: $(\\gamma \\langle x, x'\\rangle + r)^d$ , where $d$ is specified by parameter `degree`, $r$ by `coef0`.\n",
    "        - **rbf**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: $\\exp(-\\gamma \\|x-x'\\|^2)$, where $\\gamma$ is specified by parameter `gamma`, must be greater than `0`.\n",
    "        - **sigmoid**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: $\\tanh(\\gamma \\langle x,x'\\rangle + r)$, where $r$ is specified by `coef0`.\n",
    "    - Set kernel parameter :\n",
    "        - set `degree` :  use method `.setDegree()`\n",
    "        - set `gamma` : use method `.setGamma()`\n",
    "        - set `coef0` : use method `.setCoef0()`\n",
    "- method `.setTermCriteria(criteria_type, maxCount, epsilon)`:\n",
    "    - where `criteria_type` :\n",
    "        - `cv2.TERM_CRITERIA_MAX_ITER` : the maximum number of iterations or elements to compute\n",
    "        - `cv2.TERM_CRITERIA_EPS` : the desired accuracy or change in parameters at which the iterative algorithm stops\n",
    "        - `cv2.TERM_CRITERIA_MAX_ITER` + `cv2.TERM_CRITERIA_EPS`\n",
    "        - `maxCount` and `epsilon` is termination value for each selected createria by `criteria_type` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **SVR (Support Vector Regression)** \n",
    "    - The value of $ϵ$ **epsilon** defines a **margin** of tolerance where no penalty is given to errors\n",
    "    - The larger **epsilon** is the larger errors \n",
    "\n",
    "![](resource/epsilon_svmjpg.jpg)\n",
    "\n",
    "- **SVC (Support Vector Classification)** \n",
    "    - The value of $C$ define **regularization parameter**. The strength of the regularization is **inversely** proportional to $C$. Must be strictly positive. <br>\n",
    "<img src=\"resource/SVM-C.gif\" style=\"width:300px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = cv2.ml.SVM_create()\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "svm.setKernel(cv2.ml.SVM_LINEAR)\n",
    "svm.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.train(x_train, cv2.ml.ROW_SAMPLE, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 10\n",
    "height = 10\n",
    "\n",
    "plot_x = []\n",
    "plot_y = []\n",
    "for i in range(width):\n",
    "    for j in range(height):\n",
    "        y = svm.predict(np.array([[i,j]], dtype=np.float32))[1]\n",
    "        plot_y.append(y)\n",
    "        plot_x.append([i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x = np.array(plot_x)\n",
    "plot_y = np.array(plot_y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(plot_x[:, 0], plot_x[:, 1], c=plot_y, s=200, cmap='rainbow')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with LBPH for Facerecognitiong (OpenCV ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Install library **Scikit-Learn** & **Scikit-Image**: <br>\n",
    "`pip install scikit-learn` <br>\n",
    "`pip install scikit-image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dataset(images_class, label):\n",
    "    # show data for 1 class\n",
    "    plt.figure(figsize=(14,5))\n",
    "    k = 0\n",
    "    for i in range(1,6):\n",
    "        plt.subplot(1,5,i)\n",
    "        try :\n",
    "            plt.imshow(images_class[k][:,:,::-1])\n",
    "        except :\n",
    "            plt.imshow(images_class[k], cmap='gray')\n",
    "        plt.title(label)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        k += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"dataset/\"\n",
    "\n",
    "names = []\n",
    "images = []\n",
    "for folder in os.listdir(dataset_folder):\n",
    "    for name in os.listdir(os.path.join(dataset_folder, folder))[:5]: # limit only 70 face per class\n",
    "        if name.find(\".jpg\") > -1 :\n",
    "            img = cv2.imread(os.path.join(dataset_folder + folder, name))\n",
    "            images.append(img)\n",
    "            names.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(names)\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    \n",
    "    ids = np.where(label== np.array(names))[0]\n",
    "    images_class = images[ids[0] : ids[-1] + 1]\n",
    "    show_dataset(images_class, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- crop, resize & convert to grayscale for detected face area using **cascade classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img, idx):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    try :\n",
    "        x, y, w, h = faces[0]\n",
    "\n",
    "        img = img[y:y+h, x:x+w]\n",
    "        img = cv2.resize(img, (100, 100))\n",
    "    except :\n",
    "        print(\"Face not found in image index\", i)\n",
    "        img = None\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "croped_images = []\n",
    "for i, img in enumerate(images) :\n",
    "    img = detect_face(img, i)\n",
    "    if img is not None :\n",
    "        croped_images.append(img)\n",
    "    else :\n",
    "        del names[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    \n",
    "    ids = np.where(label== np.array(names))[0]\n",
    "    images_class = croped_images[ids[0] : ids[-1] + 1] # select croped images for each class\n",
    "    show_dataset(images_class, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Label Encoding (Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(names)\n",
    "\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_vec = le.transform(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split dataset (75% train, 25% test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np.array(croped_images, dtype=np.float32),   # input data\n",
    "                                                    np.array(name_vec),                            # target/output data \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape, x_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LBPH without `cv2.face.LBPHFaceRecognizer_create()`\n",
    "\n",
    "## 4.1 Find LBP Histograms for each image data using Scikit-Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- function `local_binary_pattern(img, P, R)`\n",
    "- parameter :\n",
    "    - `P` : `int`, Number of circularly symmetric neighbour set points (number of sample point).\n",
    "    - `R` : `float`, Radius of circle.<br>\n",
    "    \n",
    "<img src=\"resource/lbp-param.jpg\" style=\"width:300px\"></img>\n",
    "- default on OpenCV LPBH Recognizer :\n",
    "    - `P` : 8\n",
    "    - `R` : 1\n",
    "- each value in LBP image is range from `[0, numPoints + 2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 8\n",
    "R = 1\n",
    "img = x_train[0]\n",
    "lbp_img = local_binary_pattern(img, P=P, R=R, method=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = np.histogram(lbp_img.ravel(),                          \n",
    "                 bins=2**P,                          \n",
    "                 range=(0, 2**P),\n",
    "                 density=True)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "axis = np.arange(len(H))\n",
    "plt.bar(axis, H)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Implement LBPH Face Recognition without OpenCV\n",
    "- Feature : LBP (Scikit-Learn)\n",
    "- Classifier : Nearest Neighbours (Scikit-Image)\n",
    "- Metric : Chi 2 (*user defined function*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBPHFaceRecognizer_custom():\n",
    "    #\n",
    "    # ----- class for LBPH + Nearest Neighbours (chi 2) ------\n",
    "    #\n",
    "    def __init__(self):\n",
    "        self.neigh = NearestNeighbors(n_neighbors=1, radius=0.4, metric=self.chi2_distance)\n",
    "        self.face_histograms = []\n",
    "        self.y = []\n",
    "    \n",
    "    def chi2_distance(self, hist1, hist2, gamma=0.5): \n",
    "        chi = gamma * np.sum(((hist1 - hist2) ** 2) / (hist1 + hist2 + 1e-7))\n",
    "        return chi\n",
    "    \n",
    "    def find_lbp_histogram(self, image, P=8, R=1, eps=1e-7, n_window=(8,8)):\n",
    "        E = []\n",
    "        h, w = image.shape\n",
    "        h_sz = int(np.floor(h/n_window[0]))\n",
    "        w_sz = int(np.floor(w/n_window[1]))\n",
    "        lbp_img = local_binary_pattern(image, P=P, R=R, method=\"default\")\n",
    "        for (x, y, C) in self.sliding_window(lbp_img, stride=(h_sz, w_sz), window=(h_sz, w_sz)):\n",
    "            if C.shape[0] != h_sz or C.shape[1] != w_sz:\n",
    "                continue\n",
    "            H = np.histogram(C,                          \n",
    "                             bins=2**P, \n",
    "                             range=(0, 2**P),\n",
    "                             density=True)[0] \n",
    "            \n",
    "            H = H.astype(\"float\")\n",
    "            H /= (H.sum() + eps)\n",
    "            E.extend(H)\n",
    "        return E\n",
    "    \n",
    "    def sliding_window(self, image, stride, window):\n",
    "        for y in range(0, image.shape[0], stride[0]):\n",
    "            for x in range(0, image.shape[1], stride[1]):\n",
    "                yield (x, y, image[y:y + window[1], x:x + window[0]])\n",
    "                   \n",
    "    def train(self, x, y):\n",
    "        self.y = y\n",
    "        self.face_histograms = [self.find_lbp_histogram(img) for img in x]\n",
    "        self.neigh.fit(self.face_histograms)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        hists = [self.find_lbp_histogram(img) for img in x]\n",
    "        dist, idx = self.neigh.kneighbors(hists)\n",
    "        pred_id = np.array([self.y[i[0]] for i in idx])\n",
    "        return pred_id, dist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lbph_custom = LBPHFaceRecognizer_custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lbph_custom.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict to all test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model_lbph_custom.predict(x_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- report summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=labels,normalize=False,\n",
    "                      title='Confusion matrix For - LBPH Custom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"== Classification Report for - LBPH Custom ==\\n\")\n",
    "print(classification_report(y_test, \n",
    "                            y_predict, \n",
    "                            target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Compare with LBPHFaceRecognizer_create() in OpenCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbph = cv2.face.LBPHFaceRecognizer_create()\n",
    "lbph.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict to all test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = [lbph.predict(x)[0] for x in x_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- result summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=labels,normalize=False,\n",
    "                      title='Confusion matrix - LBPH OpenCV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"== Classification Report - LBPH OpenCV ==\\n\")\n",
    "print(classification_report(y_test, \n",
    "                            y_predict, \n",
    "                            target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SVM and LBPH for Facrecognition \n",
    "\n",
    "## 5.1 SVM OpenCV + LBPH Scikit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBPH_SVM_Recognizer_V1():\n",
    "    #\n",
    "    # ----- class for LBPH Scikit + SVM OpenCV------\n",
    "    #\n",
    "    def __init__(self, max_iter=100, epsilon=0.001, C=100, Gamma=0.001):\n",
    "        self.svm = cv2.ml.SVM_create()\n",
    "        self.svm.setKernel(cv2.ml.SVM_CHI2)\n",
    "        self.svm.setType(cv2.ml.SVM_C_SVC)\n",
    "        self.svm.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER, max_iter, epsilon))\n",
    "        self.svm.setC(C)           \n",
    "        self.svm.setGamma(Gamma) \n",
    "        \n",
    "        self.face_histograms = []\n",
    "        self.y = []\n",
    "    \n",
    "    def find_lbp_histogram(self, image, P=8, R=1, eps=1e-7, n_window=(8,8)):\n",
    "        E = []\n",
    "        h, w = image.shape\n",
    "        h_sz = int(np.floor(h/n_window[0]))\n",
    "        w_sz = int(np.floor(w/n_window[1]))\n",
    "        lbp_img = local_binary_pattern(image, P=P, R=R, method=\"default\")\n",
    "        for (x, y, C) in self.sliding_window(lbp_img, stride=(h_sz, w_sz), window=(h_sz, w_sz)):\n",
    "            if C.shape[0] != h_sz or C.shape[1] != w_sz:\n",
    "                continue\n",
    "            H = np.histogram(C,                          \n",
    "                             bins=2**P, \n",
    "                             range=(0, 2**P),\n",
    "                             density=True)[0] \n",
    "            E.extend(H)\n",
    "        return E\n",
    "    \n",
    "    def sliding_window(self, image, stride, window):\n",
    "        for y in range(0, image.shape[0], stride[0]):\n",
    "            for x in range(0, image.shape[1], stride[1]):\n",
    "                yield (x, y, image[y:y + window[1], x:x + window[0]])\n",
    "                   \n",
    "    def train(self, x, y):\n",
    "        self.y = y\n",
    "        self.face_histograms = [self.find_lbp_histogram(img) for img in x]\n",
    "        hist_mat = np.array(self.face_histograms, dtype=np.float32)\n",
    "        self.svm.train(hist_mat, cv2.ml.ROW_SAMPLE, y)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        hists = [self.find_lbp_histogram(img) for img in x]\n",
    "        hist_mat = np.array(hists, dtype=np.float32)\n",
    "        ret, idx = self.svm.predict(hist_mat, True)\n",
    "        confidence = 1.0 / (1.0 + np.exp(-ret)) # convert retVal to confidence level (0-1) sigmoid\n",
    "        return idx, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbph_svm_model_v1 = LBPH_SVM_Recognizer_V1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbph_svm_model_v1.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save & load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbph_svm_model_v1.svm.save(\"lbph_svm_model_v1.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbph_svm_model_v1.svm.load(\"lbph_svm_model_v1.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict to all data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lbph_svm_model_v1.predict(x_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- result summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=labels,normalize=False,\n",
    "                      title='Confusion matrix - SVM OpenCV + LBPH Scikit ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"== Classification Report - SVM OpenCV + LBPH Scikit ==\\n\")\n",
    "print(classification_report(y_test, \n",
    "                            y_predict, \n",
    "                            target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 SVM Scikit + LBPH Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBPH_SVM_Recognizer_V2():\n",
    "    #\n",
    "    # ----- class for LBPH Scikit + SVM Scikit------\n",
    "    #\n",
    "    def __init__(self, C=100, Gamma=0.001):\n",
    "        self.svm = SVC(kernel='precomputed', C=C, gamma=Gamma)\n",
    "        self.chi2 = DistanceMetric.get_metric('pyfunc', func=self.chi2_distance)\n",
    "        self.face_histograms = []\n",
    "        self.hist_mat = []\n",
    "        \n",
    "    def chi2_distance(self, hist1, hist2, gamma=0.5): \n",
    "        chi = - gamma * np.sum(((hist1 - hist2) ** 2) / (hist1 + hist2 + 1e-7)) \n",
    "        return chi\n",
    "\n",
    "    def find_lbp_histogram(self, image, P=8, R=1, eps=1e-7, n_window=(8,8)):\n",
    "        E = []\n",
    "        h, w = image.shape\n",
    "        h_sz = int(np.floor(h/n_window[0]))\n",
    "        w_sz = int(np.floor(w/n_window[1]))\n",
    "        lbp_img = local_binary_pattern(image, P=P, R=R, method=\"default\")\n",
    "        for (x, y, C) in self.sliding_window(lbp_img, stride=(h_sz, w_sz), window=(h_sz, w_sz)):\n",
    "            if C.shape[0] != h_sz or C.shape[1] != w_sz:\n",
    "                continue\n",
    "            H = np.histogram(C,                          \n",
    "                             bins=2**P, \n",
    "                             range=(0, 2**P),\n",
    "                             density=True)[0] \n",
    "            \n",
    "            H = H.astype(\"float\")\n",
    "            H /= (H.sum() + eps)\n",
    "            E.extend(H)\n",
    "        return E\n",
    "    \n",
    "    def sliding_window(self, image, stride, window):\n",
    "        for y in range(0, image.shape[0], stride[0]):\n",
    "            for x in range(0, image.shape[1], stride[1]):\n",
    "                yield (x, y, image[y:y + window[1], x:x + window[0]])\n",
    "                   \n",
    "    def train(self, x, y):\n",
    "        self.face_histograms = [self.find_lbp_histogram(img) for img in x]\n",
    "        self.hist_mat = np.array(self.face_histograms, dtype=np.float32)\n",
    "        K = self.chi2.pairwise(self.hist_mat,self.hist_mat)\n",
    "        self.svm.fit(K, y)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        hists = [self.find_lbp_histogram(img) for img in x]\n",
    "        hist_mat = np.array(hists, dtype=np.float32)\n",
    "        K = self.chi2.pairwise(hist_mat, self.hist_mat)\n",
    "        idx = self.svm.predict(K)\n",
    "\n",
    "        return idx, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbph_svm_model_v2 = LBPH_SVM_Recognizer_V2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lbph_svm_model_v2.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save & load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pickle-mixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model, filename, path=\"\"): \n",
    "    with open(os.path.join(path, filename), 'wb') as out_name:\n",
    "        pickle.dump(model, out_name, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_model(filename, path=\"\"):\n",
    "    with open(os.path.join(path, filename), 'rb') as in_name:\n",
    "        model = pickle.load(in_name)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(lbph_svm_model_v2, \"lbph_svm_model_v2.pkl\", path=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbph_svm_model_v2 = read_model(\"lbph_svm_model_v2.pkl\", path=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict to all test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lbph_svm_model_v2.predict(x_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- result summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=labels, normalize=False,\n",
    "                      title='Confusion matrix - SVM + LBPH Scikit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"== Classification Report - SVM + LBPH Scikit ==\\n\")\n",
    "print(classification_report(y_test, y_predict, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Apply our face dataset\n",
    "\n",
    "- colect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "my_name = \"Yunus\"\n",
    "i = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret :\n",
    "        cv2.imshow(\"Capture Photo\", frame)\n",
    "        cv2.imwrite(\"my_face/%s_%04d.jpg\" %  (my_name, i), frame)\n",
    "        \n",
    "        if cv2.waitKey(100) == ord('q') or i == 71:\n",
    "            break\n",
    "        i += 1    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- move our face to dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! Dir dataset\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir dataset\\Yunus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! move my_face\\* dataset\\Yunus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rerun Load dataset, Traing & Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Test Realtime Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ped(img, label, x0, y0, xt, yt, color=(255,127,0), text_color=(255,255,255)):\n",
    "\n",
    "    (w, h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 + baseline),  \n",
    "                  (max(xt, x0 + w), yt), \n",
    "                  color, \n",
    "                  2)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 - h),  \n",
    "                  (x0 + w, y0 + baseline), \n",
    "                  color, \n",
    "                  -1)  \n",
    "    cv2.putText(img, \n",
    "                label, \n",
    "                (x0, y0),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "                0.5,                          \n",
    "                text_color,                \n",
    "                1,\n",
    "                cv2.LINE_AA) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# --------- using SVM scikit + LBPH Scikit -------------\n",
    "model = read_model(\"lbph_svm_model_v2.pkl\", path=\"\")\n",
    "\n",
    "# --------- using SVM OpenCV + LBPH Scikit -------------\n",
    "#model = LBPH_SVM_Recognizer_V2()\n",
    "#model = model.svm.load(\"lbph_svm_model_v1.yml\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened() :\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            \n",
    "            face_img = gray[y:y+h, x:x+w]\n",
    "            face_img = cv2.resize(face_img, (100, 100))\n",
    "            \n",
    "            idx, confidence = model.predict(face_img)\n",
    "            label_text = \"%s (%.2f %%)\" % (labels[idx], confidence)\n",
    "            \n",
    "            frame = draw_ped(frame, label_text, x, y, x + w, y + h, color=(0,255,255), text_color=(50,50,50))\n",
    "       \n",
    "        cv2.imshow('Detect Face', frame)\n",
    "    else :\n",
    "        break\n",
    "    if cv2.waitKey(10) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
